<p align="center">
  <img src="docs/Wordmark%20Logo%20for%20ConsciousDB.svg" alt="ConsciousDB Wordmark" width="420" />
</p>

# ConsciousDB ‚Äì Your Vector Database *Is* the Model (formerly "consciousdb-sidecar")

> ‚ö†Ô∏è **v3 SDK‚ÄëFirst Migration:** The legacy sidecar HTTP pattern is now optional. The canonical integration path is the in‚Äëprocess SDK (no server). The package name is `consciousdb` (old `consciousdb-sidecar` deprecated). The high‚Äëlevel stable entrypoint is `solve_query` (surfaced via `ConsciousClient.query`). Server extras remain for transitional deployments.

<!-- Badges -->
![CI](https://img.shields.io/github/actions/workflow/status/Maverick0351a/consciousdb/test.yml?branch=main&label=CI)
![Coverage](https://img.shields.io/codecov/c/github/Maverick0351a/consciousdb/main?logo=codecov&label=coverage)
<a href="https://app.codecov.io/gh/Maverick0351a/consciousdb" target="_blank"><img src="https://codecov.io/gh/Maverick0351a/consciousdb/branch/main/graph/badge.svg" alt="Codecov" /></a>
![License](https://img.shields.io/badge/License-BSL%201.1-blue)

> Stop stacking opaque rerankers. ConsciousDB turns the structure already latent in your vectors into an **explainable retrieval intelligence layer** ‚Äì no training, no drift, full receipts.

> Elevator (non‚Äëtechnical): **ConsciousDB makes vector search explainable. See exactly *why* results rank‚Äîwithout adding another AI model.**

## üì¶ Install
Renamed package: publish / install as `consciousdb` (the previous `consciousdb-sidecar` name is deprecated).

SDK‚Äëonly (lean: numpy, scipy, pydantic):
```bash
pip install consciousdb
```
With optional legacy HTTP server + metrics layer:
```bash
pip install "consciousdb[server]"
```
Add connectors / embedders as needed, e.g.:
```bash
pip install "consciousdb[server,connectors-pgvector,embedders-sentence]"
```
Why slim? The default install should not pull a web server if you just want an in‚Äëprocess ranking + receipt layer.

## ÔøΩüö© The Problem
Vector search gives you similarity ‚Äì but not *understanding*. Teams struggle to answer:
- *Why* did these items outrank others?
- *How* do the results relate to each other (support / redundancy / gaps)?
- *What* specific structure change would improve relevance?

Typical fixes add another neural reranker (more latency, drift, & opacity) or a heavy offline graph build. Both increase operational surface and hide reasoning.

## üéØ Core Idea (Database-as-Model)
Instead of inserting a new model, each query induces a tiny, ephemeral k‚ÄëNN graph over the recalled candidates. A fast **structure‚Äëaware energy solve** (symmetric positive definite system) refines embeddings and produces a conserved ŒîH (energy uplift) that naturally decomposes per item. That decomposition *is* the ranking explanation.

| You Want | Traditional Path | ConsciousDB Path |
|----------|------------------|------------------|
| Better ordering | Add / fine‚Äëtune model | Solve energy on existing vectors |
| Explanation | Post‚Äëhoc approximations | Built‚Äëin per‚Äëitem ŒîH terms |
| Low ops overhead | Maintain model infra | Lightweight CPU solve layer |
| Stability | Weight drift & retrains | No learned weights, fresh graph per query |
| Auditability | Sparse logs | Structured receipt JSON |

## üíé What You Get
**Energy Receipt** ‚Äì `deltaH_total` plus per-item components (coherence contribution, anchor / ground terms, neighbors, timings, fallback reasons).  
**Model‚ÄëFree Uplift** ‚Äì Improved ordering using only your existing vectors.  
**Transparent Math** ‚Äì Reproducible linear algebra; no hidden gradient soup.  
**Low Latency** ‚Äì Typical local/mock ~50 ms P95 for k‚â§8 (CPU).  
**Bring Your Own Vector DB** ‚Äì Pinecone, pgvector, Chroma, Vertex AI, in‚Äëmemory.

## üìä Results In Practice *(early internal / synthetic reference)*
| Metric | Improvement / Figure | Notes |
|--------|----------------------|-------|
| nDCG uplift | **~21%** vs raw cosine | Synthetic eval harness (see `docs/BENCHMARKS.md`) |
| P95 latency | **~50 ms** | Local/mock k‚â§8, CPU only |
| Follow-up LLM calls | **~35% fewer** | Higher initial relevance reduces clarifying turns |

*(Real public benchmark numbers will be published as dataset loaders land.)*

## ü§î Why Not Just...
| Option | Hidden Cost | Still Lacks |
|--------|-------------|-------------|
| Add a neural reranker | Extra model infra, finetuning, drift | Native explanation, per-item energy traces |
| Build a knowledge graph | Heavy ETL, schema churn, stale edges | On-demand freshness, low ops footprint |
| Tune / re-embed corpus | Labeling effort, loss of generality | Live structural attribution, audit trail |

**ConsciousDB:** Light, explainable, works with what you already have.

## ‚ú® Quickstart (Pure SDK ‚Äì Recommended)
```python
from consciousdb import ConsciousClient

client = ConsciousClient()  # uses default in‚Äëmemory mock unless env connectors set
result = client.query("vector governance controls", k=6, m=200)
print(result.deltaH_total, result.items[0].id)
```
Override connectors / embedders with environment variables or by passing instances to `ConsciousClient(...)` (see Connectors section below). The call internally performs:
1. Embed query
2. Recall M candidates from your vector DB (or mock)
3. Build ephemeral mutual kNN graph
4. Run SPD energy solve (CG)
5. Decompose ŒîH into per-item parts
6. Rank (optionally diversify) and return a structured receipt

Return object fields (stable): `items`, `deltaH_total`, `diagnostics` (timings, cg_iters, redundancy, fallback, parameters).

For lower-level experimentation you can import `from engine.solve import solve_query` directly.

## ‚ú® Quickstart (Local Mock via Server Extra)
```bash
python -m venv .venv
. ./.venv/Scripts/Activate.ps1   # PowerShell
pip install "consciousdb[server]"
$env:USE_MOCK='true'
uvicorn api.main:app --port 8080 --reload
```
Query:
```bash
curl -s -X POST http://localhost:8080/query \
  -H "content-type: application/json" \
  -d '{"query":"vector governance controls","k":6,"m":400}' | jq '.items[0],.diagnostics.deltaH_total'
```
Full schema: see `docs/API.md` & `docs/RECEIPTS.md`.

## ‚ö° See It Work (60 Seconds) ‚Äì Server Path
Requires Docker + docker compose plugin.
```bash
git clone https://github.com/Maverick0351a/consciousdb
cd consciousdb
docker compose up -d       # launches API + (optionally) demo if compose file present
sleep 3
curl -s -X POST http://localhost:8080/query -H "content-type: application/json" \
  -d '{"query":"vector governance controls","k":6,"m":300}' | jq '.diagnostics.deltaH_total'
```
Optional (if demo container configured): open http://localhost:8501

## üß™ High-Level Flow (Conceptual)
```
Query ‚Üí Vectors ‚Üí Local Graph ‚Üí Physics Solve ‚Üí Explained Rankings (Receipt)
```
Minimal mental model:
1. Pull candidates (M) from your existing vector DB.
2. Construct ephemeral similarity graph (only these M nodes).
3. Run a fast energy minimization (convergence in a handful of iterations).
4. Decompose total uplift (ŒîH) into per-item parts.
5. Rank + return receipt.

<details>
<summary><strong>Technical Path (click to expand)</strong></summary>

```mermaid
flowchart LR
  Q[Query] --> E[Embed]
  E --> R[Recall M]
  R --> G[Mutual kNN Graph]
  G --> S[SPD Solve (CG)]
  S --> A[ŒîH Attribution]
  A --> RK[Rank + Diversify]
  RK --> RC[Receipt JSON]
```

- Solve: Jacobi‚Äëpreconditioned CG over normalized Laplacian + anchor/ground diagonals.
- Attribution: Per-node split (coherence/anchor/ground) sums exactly to `deltaH_total`.
- Ranking blend: z‚Äëscored coherence uplift + structure‚Äësmoothed alignment (optional MMR when redundancy > threshold).

</details>

## üßæ Receipt Snapshot
```json
{
  "deltaH_total": 2.314,
  "items": [{ "id": "doc_42", "coherence_drop": 0.156, "anchor_drop": -0.021, "neighbors": [{"id":"doc_17","weight":0.82}] }],
  "redundancy": 0.31,
  "cg_iters": 9,
  "fallback": false,
  "timings_ms": { "solve": 22.5, "total": 50.1 }
}
```
See full evolution in `docs/RECEIPTS.md`.

<!-- (Pure SDK section consolidated above) -->

## üîå Connectors (BYOVDB)
```bash
# pgvector
$env:CONNECTOR='pgvector'
$env:PG_DSN='postgresql://user:pass@host:5432/db'

# Pinecone
$env:CONNECTOR='pinecone'
$env:PINECONE_API_KEY='...'
$env:PINECONE_INDEX='my-index'

# Chroma
$env:CONNECTOR='chroma'
$env:CHROMA_HOST='http://localhost:8000'
$env:CHROMA_COLLECTION='docs'
```
Embedders: `sentence_transformer` | `openai` | `vertex`. Configure via env (see `docs/CONFIGURATION.md`).

## ‚úÖ When to Use
| Scenario | Benefit |
|----------|---------|
| RAG answer quality plateaued | Structure coherence signal beyond raw cosine |
| Need explainability / audit | Deterministic receipt; per-item decomposition |
| Avoid model fleet creep | No training / no extra neural runtime |
| Cost pressure | Substitute paid reranker API; fewer follow-up LLM calls |

## ‚öñÔ∏è ConsciousDB vs Rerankers (Condensed)
| Aspect | Neural Reranker | ConsciousDB |
|--------|-----------------|-------------|
| Extra model hosting | Yes | No |
| Training / finetune | Required | None |
| Interpretability | Low | High (receipt) |
| Drift Surface | Weights drift | None (no weights) |
| Latency Source | Model inference | Small SPD solve |
| Audit Trail | Add-on | Built-in |

## üìà Benchmarks & Metrics
Benchmark harness + methodology: `docs/BENCHMARKS.md`.  
Operational metrics & SLOs: `docs/OPERATIONS.md`.

## üîÑ Adaptive (Optional)
Feedback-driven alpha suggestion & bandit exploration are *opt‚Äëin*; details in `docs/ADAPTIVE.md`.

---

## üìñ Documentation Index
| Topic | Where |
|-------|-------|
| API & Schemas | `docs/API.md` |
| Receipts Spec | `docs/RECEIPTS.md` |
| Configuration Matrix | `docs/CONFIGURATION.md` |
| Architecture | `docs/ARCHITECTURE.md` |
| Security Model | `docs/SECURITY.md` |
| Pricing Rationale | `docs/PRICING_MODEL.md` |
| Adaptive Loop | `docs/ADAPTIVE.md` |
| Benchmarks | `docs/BENCHMARKS.md` |

## üß≠ Migrating from Sidecar to SDK
| Before (Sidecar) | After (SDK) | Notes |
|------------------|------------|-------|
| POST /query JSON | `client.query(q, k, m)` | Same schema, now direct object return |
| Env: USE_MOCK | Auto in-memory mock | Provide real connector envs to switch |
| curl + jq | Python call | Lower latency, fewer hops |
| Custom reranker service | Built-in energy solve | ŒîH receipt is explanation |
| Server scaling | In-process function | Scale with your app threads |

Deprecation timeline: the HTTP server extra will remain until at least v3.x LTS; receipt field backward compatibility maintained (additive only).

## üõ† Contributing
Small, tested PRs welcome. Preserve backward compatibility of receipt fields; add new diagnostics additively. See `CONTRIBUTING.md`.

## üß™ Examples
Quickstart script: `examples/quickstart_sdk.py`

Run (PowerShell):
```powershell
python examples/quickstart_sdk.py
```
Outputs top results and `deltaH_total` plus demonstrates both `ConsciousClient` and direct `solve_query` usage.

## üß™ Testing & Coverage Strategy
The test suite uses a dual-mode approach to balance speed and authentic solver coverage:

- Default: a lightweight stub of `solve_query` (activated via an autouse fixture) speeds up most tests.
- Opt-in real solver: mark tests with `@pytest.mark.real_solver` (or set env `REAL_SOLVER=1`) to exercise the full CG solve, energy decomposition, ranking, and MMR logic.

Why: The energy solve touches numerical branches (gating, fallback, redundancy, mmr) that would otherwise show as uncovered. By only enabling it where needed we keep total runtime low while keeping coverage >85% on core engine modules.

Key real-solver tests:
- `tests/test_real_solver_path.py` ‚Äì full end-to-end receipt & energy path.
- `tests/test_rank_energy_mm.py` ‚Äì MMR path, redundancy computation.
- `tests/test_solver_branches.py` ‚Äì baseline early gate and forced fallback branches.

To run the full suite with authentic solver paths:
```powershell
$env:REAL_SOLVER='1'; pytest -q --cov=engine
```
(Or selectively remove the stub fixture in `tests/conftest.py`).

## üîê License
Business Source License 1.1 ‚Üí converts to Apache 2.0 on **2028‚Äë10‚Äë05**. Evaluation & internal non‚Äëprod use are free; commercial prod use requires a commercial grant until the change date. See `LICENSE` + `docs/LICENSING.md`.

> Elevator: *ConsciousDB turns your existing vector database into the model‚Äîan explainable, structure‚Äëaware ranking layer with auditable energy receipts instead of another opaque reranker.*
